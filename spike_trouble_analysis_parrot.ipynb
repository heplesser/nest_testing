{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a40bb1-0d20-4996-8be7-b89f71402b60",
   "metadata": {},
   "source": [
    "# Analyse problems with deliver_events_first\n",
    "\n",
    "- See test set `test_bad_connections.py`/`run_bad_connections.py`\n",
    "    - One population of 50 parrot neurons\n",
    "    - All neurons receive input spike from spike generator at 0.1 ms\n",
    "    - All neurons produce output spike at 0.2 ms; these are transmitted locally from spike gen to parrot\n",
    "    - Neurons are connected to other neurons in same population with delay 0.1 ms\n",
    "    - Thus spikes fired by parrots at 0.2 ms evoke output from parrots at 0.3 ms; these spikes are transmitted via MPI\n",
    "    - Sources are given as two arrays (good/bad) and connected one-to-one to targets 1..50, in-degree 1\n",
    "        - For both good and bad sources, several sources have an out-degree > 1\n",
    "    - Expected behavior when simulating for 0.3 ms: Each parrot neuron spikes once at 0.2ms and once at 0.3ms\n",
    "    - Observed behavior\n",
    "        - For the \"good\" sources, NEST behaves as expected\n",
    "        - For the \"bad\" sources, 17 additional spikes are fired at 0.3 ms\n",
    "- Analysis indicates that problems are related to communication of target information from post- to presynaptic side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ebca0-48a8-4208-9b43-70d796bf556d",
   "metadata": {},
   "source": [
    "## Problem documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e50415-1588-4e2e-9d35-21a6a5109fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70680731-f78b-4ef4-b481-5399b512c984",
   "metadata": {},
   "source": [
    "### Load source information\n",
    "\n",
    "NB: Requires NEST in Python path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8bf9c09-4606-422c-891d-55f5ddda3cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              -- N E S T --\n",
      "  Copyright (C) 2004 The NEST Initiative\n",
      "\n",
      " Version: def_debug@bbe555867\n",
      " Built: Feb 28 2023 00:47:45\n",
      "\n",
      " This program is provided AS IS and comes with\n",
      " NO WARRANTY. See the file LICENSE for details.\n",
      "\n",
      " Problems or suggestions?\n",
      "   Visit https://www.nest-simulator.org\n",
      "\n",
      " Type 'nest.help()' to find out more about NEST.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from run_bad_connections import good_sources, bad_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902e27b9-1d04-49d2-8b6c-1a7d90413ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 50, 37, 13, 47, 29, 9, 46, 15, 10, 15, 38, 34, 29, 47, 45, 14, 23, 35, 1, 44, 3, 20, 46, 46, 13, 3, 49, 3, 48, 5, 9, 15, 28, 30, 25, 40, 30, 16, 3, 40, 40, 24, 40, 40, 17, 50, 32, 43, 42]\n"
     ]
    }
   ],
   "source": [
    "print(good_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7837f46-6034-4045-bd2b-a108e5d42c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 49, 41, 41, 9, 44, 19, 46, 9, 25, 11, 33, 46, 37, 36, 27, 45, 29, 15, 27, 21, 50, 27, 38, 3, 5, 38, 3, 41, 49, 42, 37, 36, 45, 5, 3, 21, 29, 9, 30, 34, 40, 35, 44, 41, 48, 44, 27, 36, 47]\n"
     ]
    }
   ],
   "source": [
    "print(bad_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc486bd-c043-4f5a-9e9b-ee3e6f17b39e",
   "metadata": {},
   "source": [
    "### Load spike output from test executions\n",
    "\n",
    "- Data created by runnning\n",
    "    ```\n",
    "    mpirun -np [1|2] python run_bad_connections.py . True [good|bad]\n",
    "    ```\n",
    "  and moving output files manually to `[good|bad]_log` directories\n",
    "- Files `1-0`, `2-[0|1]` contain pickled spike recorder output for 1/2 ranks and rank numbers 0 and 1 and are the same files used by `test_bad_connections.py` to transfer results between runner and checker.\n",
    "- Code below combines data from ranks and sorts to allow comparison; this is the same check as performed by the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2271a-393c-460d-bb13-b8144ef31800",
   "metadata": {},
   "source": [
    "#### Good case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1701d3ab-e561-409a-bd79-4d0ca5519156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g1 = pickle.load(open('good_log/1-0', 'rb')).sort_values(['times', 'senders'], ignore_index=True)\n",
    "g20 = pickle.load(open('good_log/2-0', 'rb'))\n",
    "g21 = pickle.load(open('good_log/2-1', 'rb'))\n",
    "g2 = pd.concat([g20, g21], ignore_index=True).sort_values(['times', 'senders'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f507918b-cade-440e-b5f8-1a1fe7f54afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(g1 == g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c0134-4278-452e-bd5a-8041d72a8442",
   "metadata": {},
   "source": [
    "#### Bad case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae7ffb0c-a17d-43d4-a8bb-411daa0a3d7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b1 = pickle.load(open('bad_log/1-0', 'rb')).sort_values(['times', 'senders'], ignore_index=True)\n",
    "b20 = pickle.load(open('bad_log/2-0', 'rb'))\n",
    "b21 = pickle.load(open('bad_log/2-1', 'rb'))\n",
    "b2 = pd.concat([b20, b21], ignore_index=True).sort_values(['times', 'senders'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de156c9-67ae-41aa-bb13-7cabddb64d80",
   "metadata": {},
   "source": [
    "- When running on single rank, behavior is as expected, same as for good case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44e8a85d-2a01-45d5-9249-90c4a74c2f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(g1 == b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933d705-d405-413f-ac0c-d28ba5608812",
   "metadata": {},
   "source": [
    "- Spikes at 0.2 are ok on two mpi ranks as well (locally transmitted spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec22df5-8dd8-45dc-a7a8-80b18652dbae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(b1.loc[b1.times==0.2] == b2.loc[b2.times==0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bf50c-81bc-42c0-92d8-2e6eba2bf639",
   "metadata": {},
   "source": [
    "#### Problems in bad case in two ranks at 0.3 ms\n",
    "- In the good case / on a single rank, each neuron fires a single spike at 0.3 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4fc2581-0677-4b90-8892-3d65a4449d28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(b1.loc[b1.times==0.3].senders == range(1, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdb85e-caf6-4533-8e65-8e33fb5457a4",
   "metadata": {},
   "source": [
    "- For the bad case and two ranks, we have extra spikes at 0.3ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56f84afc-40a2-4494-b5d3-2b4063a8bb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b2_03_s = b2.loc[b2.times==0.3].senders.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e004b23-3f40-453f-88dc-ae675d20e924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b2_03_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511c42c-a754-4ac6-a75e-ae23f87311ea",
   "metadata": {},
   "source": [
    "- 17 extra spikes\n",
    "- Confirm that all neurons have spiked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "669aaa71-963f-4d8c-887e-a0f683e7e7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(b2_03_s) == set(range(1, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc6af2-320d-472b-8962-0ce9de2e9a96",
   "metadata": {},
   "source": [
    "- Find neurons that have spikes multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "050e16fd-9fbd-4b07-9d41-f131a9d0837b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  6  8 13 15 22 24 27 31 33 40 41 42 44 46 47 49]\n"
     ]
    }
   ],
   "source": [
    "extra_spike_nrns = b2_03_s[:-1][(b2_03_s[1:] - b2_03_s[:-1]) == 0]\n",
    "print(extra_spike_nrns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c96557-dcbb-41a6-b99a-253d1f59ce96",
   "metadata": {},
   "source": [
    "- The remaining neurons have no extra spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a3605f1-6809-4d69-abcd-11fee2a47930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 7, 9, 10, 11, 12, 14, 16, 17, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 43, 45, 48, 50]\n"
     ]
    }
   ],
   "source": [
    "no_extra_spike_nrns = sorted(set(range(1, 51)) - set(extra_spike_nrns))\n",
    "print(no_extra_spike_nrns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a023d69-ced2-4024-bdd8-eb9948002228",
   "metadata": {},
   "source": [
    "- Obtain source-target pairs for connections with and without extra spikes\n",
    "    - `-1` to translate from node id to array index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47ef2944-c197-4411-bef4-e3de097ee93b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 1), (30, 40), (34, 41), (36, 15), (36, 33), (36, 49), (38, 24), (38, 27), (40, 42), (42, 31), (44, 6), (44, 44), (44, 47), (46, 8), (46, 13), (48, 46), (50, 22)]\n"
     ]
    }
   ],
   "source": [
    "extra_spike_conns = sorted((bad_sources[tgt-1], tgt) for tgt in extra_spike_nrns)\n",
    "print(extra_spike_conns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa935523-eb12-4f3b-b491-f1556fca362e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 25), (3, 28), (3, 36), (5, 26), (5, 35), (9, 5), (9, 9), (9, 39), (11, 11), (15, 19), (19, 7), (21, 21), (21, 37), (25, 10), (27, 16), (27, 20), (27, 23), (27, 48), (29, 18), (29, 38), (33, 12), (35, 43), (37, 14), (37, 32), (41, 3), (41, 4), (41, 29), (41, 45), (45, 17), (45, 34), (47, 50), (49, 2), (49, 30)]\n"
     ]
    }
   ],
   "source": [
    "no_extra_spike_conns = sorted((bad_sources[tgt-1], tgt) for tgt in no_extra_spike_nrns)\n",
    "print(no_extra_spike_conns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c2a9f-02df-47d9-9176-750b4735686f",
   "metadata": {},
   "source": [
    "- Note that several sources occur several times\n",
    "- Reduce to unique sources in both groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0d2aa8f-749c-4000-b483-de071085f499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 30, 34, 36, 38, 40, 42, 44, 46, 48, 50]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_spike_sources = sorted(set(s for s, t in extra_spike_conns))\n",
    "extra_spike_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40845475-c3b1-48b8-aeea-ecb01b2dcdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 9, 11, 15, 19, 21, 25, 27, 29, 33, 35, 37, 41, 45, 47, 49]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_extra_spike_sources = sorted(set(s for s, t in no_extra_spike_conns))\n",
    "no_extra_spike_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd252b-8d43-4dbf-ad61-4f430aba8d32",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Source lead to extra spikes if and only if they have even node ids, i.e., reside on rank 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23d5f2-8682-4001-919e-e7ca14bd54c2",
   "metadata": {},
   "source": [
    "## Trace process of building target tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9e4628e-5f90-4060-b6d4-09d7a0785456",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgts = range(1, 51)\n",
    "conns_bad = pd.DataFrame(zip(bad_sources, tgts), columns=['Src', 'Tgt'])\n",
    "conns_good = pd.DataFrame(zip(good_sources, tgts), columns=['Src', 'Tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe7476a9-100b-4b69-953d-6475e9b4ffd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_vp(conns):\n",
    "    \"\"\"For connection, add source and target virtural process, rank, and thread\"\"\"\n",
    "    conns['Sv'] = conns.Src % 4\n",
    "    conns['Tv'] = conns.Tgt % 4\n",
    "\n",
    "    conns['Sr'] = conns.Sv % 2\n",
    "    conns['Tr'] = conns.Tv % 2\n",
    "\n",
    "    conns['St'] = (conns.Sv // 2) % 2\n",
    "    conns['Tt'] = (conns.Tv // 2) % 2\n",
    "    \n",
    "    return conns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5224fff8-af34-4e84-b6dd-2beb05f0d09d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conns_bad = add_vp(conns_bad)\n",
    "conns_good = add_vp(conns_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c87877-9997-46ef-83a3-57f9d70cf90f",
   "metadata": {},
   "source": [
    "### Number of connections with sources and targets on given ranks 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80c21c69-d3cf-45b4-83c2-5deae3900c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def s_t_rank_count(conns, num_ranks=2):\n",
    "    print('Source  Target  Num of')\n",
    "    print('  rank    rank   conns')\n",
    "    print('----------------------')\n",
    "    for sr in range(num_ranks):\n",
    "        for tr in range(num_ranks):\n",
    "            print(f'{sr:6d}{tr:8d}{sum((conns.Sr == sr) & (conns.Tr == tr)):8d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2170d3e-eeda-46c0-9a65-328de3cf3dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source  Target  Num of\n",
      "  rank    rank   conns\n",
      "----------------------\n",
      "     0       0       8\n",
      "     0       1       9\n",
      "     1       0      17\n",
      "     1       1      16\n"
     ]
    }
   ],
   "source": [
    "s_t_rank_count(conns_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b33b3a8-5428-422c-a0aa-136dc3364c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source  Target  Num of\n",
      "  rank    rank   conns\n",
      "----------------------\n",
      "     0       0      12\n",
      "     0       1      12\n",
      "     1       0      13\n",
      "     1       1      13\n"
     ]
    }
   ],
   "source": [
    "s_t_rank_count(conns_good)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9dc4ed-48e3-4e8d-ba9c-14e9499c4ee7",
   "metadata": {},
   "source": [
    "### Class representing connection tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4336e6db-1b31-4f13-bed9-399eb9e0cff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConnTables:\n",
    "    \"\"\"\n",
    "    Build tables to be constructed by NEST kernel while creating and exchanging connections.\n",
    "    \n",
    "    All tables in this class have an outer MPI-rank dimension which represents the MPI rank on\n",
    "    which the corresponding table would be built. This dimension is not present in the corresponding\n",
    "    NEST code.\n",
    "    \n",
    "    The syn_id dimension is not represented in this class.\n",
    "    \n",
    "    - source_table\n",
    "        - The SourceTable built by repeated add_node() calls. It is always sorted here.\n",
    "        - In NEST, entries only contain source ID and primary flag\n",
    "        - Here we store source and target id and target thread for information purposes.\n",
    "    - compressible_sources\n",
    "        - Table as constructed by SourceTable::collect_compressible_sources()\n",
    "        - One entry per unique source neuron on thread\n",
    "        - Corresponds to SourceTable::compressible_sources_\n",
    "        - Compare with dumped csrc entries\n",
    "    - compressed_spike_data_map & compressed_spike_data\n",
    "        - Tables as constructed by SourceTable::fill_compressed_spike_data()\n",
    "        - ..._map maps source node IDs to entries in compressed_spike_data (csd)\n",
    "        - csd[rank(not in NEST)][source index from csd_map][target_thread] contains\n",
    "            local conn ID and target thread\n",
    "        - Compare with dumped csdm and csd entries\n",
    "    - target_send_buffers\n",
    "        - as built by ConnectionManager::fill_target_buffer(), but without resizing/blocking\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, conns, n_vp, n_mpi):\n",
    "        \"\"\"\n",
    "        conns: (src, tgt) pairs\n",
    "        n_vp: number of virtual processes\n",
    "        n_mpi: number of mpi ranks\n",
    "        \"\"\"\n",
    "        \n",
    "        assert n_vp % n_mpi == 0\n",
    "        \n",
    "        self.conns = list(conns)\n",
    "        self.n_vp = n_vp\n",
    "        self.n_mpi = n_mpi\n",
    "        self.n_thr = n_vp // n_mpi\n",
    "        \n",
    "        self._build_source_table()\n",
    "        self._collect_compressible_sources_per_thread()\n",
    "        self._compress_source_data_per_rank()\n",
    "        self._build_send_buffers()\n",
    "        self._build_target_table()\n",
    "        \n",
    "    def _get_rank_thread(self, nid):\n",
    "        vp = nid % self.n_vp\n",
    "        rk = vp % self.n_mpi\n",
    "        tr = vp // self.n_mpi\n",
    "        return rk, tr\n",
    "    \n",
    "    def _build_source_table(self):\n",
    "        self.source_table = [[[] for _ in range(self.n_thr)] for _ in range(self.n_mpi)]\n",
    "        for src, tgt in self.conns:\n",
    "            s_rnk, s_thr = self._get_rank_thread(src)\n",
    "            t_rnk, t_thr = self._get_rank_thread(tgt)\n",
    "            self.source_table[t_rnk][t_thr].append((src, tgt, t_thr))\n",
    "\n",
    "        for l in self.source_table:\n",
    "            for ll in l:\n",
    "                ll.sort()\n",
    "            \n",
    "    @staticmethod        \n",
    "    def _compress_one_thread(targets_source_tab):\n",
    "        \"\"\"Helper for _compress_sources()\"\"\"\n",
    "\n",
    "        ctab = []\n",
    "        lcid = -1\n",
    "        last_gid = -1\n",
    "        for src, tgt, tgt_thr in targets_source_tab:\n",
    "            lcid += 1\n",
    "            if src != last_gid:\n",
    "                last_gid = src\n",
    "                ctab.append((src, (tgt_thr, lcid)))\n",
    "        return ctab\n",
    "\n",
    "    def _collect_compressible_sources_per_thread(self):\n",
    "        \"\"\"\n",
    "        Compress sources on each thread separately, so each src appears only once.\n",
    "        \"\"\"\n",
    "        self.compressible_sources = [\n",
    "            [self._compress_one_thread(thr_tab) for thr_tab in rank_tab] \n",
    "            for rank_tab in self.source_table]\n",
    "\n",
    "    def _compress_source_data_per_rank(self):\n",
    "        \n",
    "        self.compressed_spike_data_map = []\n",
    "        self.compressed_spike_data = []\n",
    "        \n",
    "        for comp_sources in self.compressible_sources:  # outer loop over MPI processes\n",
    "            cmap = {}\n",
    "            csd = []\n",
    "            for thread_idx, comp_sources_on_thread in enumerate(comp_sources):\n",
    "                for src, (tgt_thr, lcid) in comp_sources_on_thread:\n",
    "                    assert thread_idx == tgt_thr   # consistency check\n",
    "                    if src not in cmap:\n",
    "                        cmap[src] = len(csd)\n",
    "                        csd.append([[] for _ in range(self.n_thr)])\n",
    "                    six = cmap[src]\n",
    "                    csd[six][tgt_thr].append({'lcid': lcid, 'tgt_thr': tgt_thr})\n",
    "            self.compressed_spike_data_map.append(cmap)\n",
    "            self.compressed_spike_data.append(csd)\n",
    "            \n",
    "    def _build_send_buffers(self):\n",
    "        \"\"\"\n",
    "        From csd/csdm, compose send buffers for presynaptic exchange.\n",
    "        \n",
    "        Logic:\n",
    "         - Each rank has one send buffer for each other rank\n",
    "         - Go through compressed_spike_data_map\n",
    "         - For each source neuron, determine rank responsible for source neuron\n",
    "         - Append csd_map entry to send buffer for that rank\n",
    "         - After exchange, each rank then will have csd_map entries for all spikes it needs to send\n",
    "        \"\"\"\n",
    "        \n",
    "        self.target_send_buffers = []\n",
    "\n",
    "        for csd_map in self.compressed_spike_data_map:  # outer loop over MPI processes\n",
    "            send_buffers = [[] for _ in range(self.n_mpi)]  # one buffer for each rank to send to\n",
    "            for src, tgt_data in csd_map.items():\n",
    "                s_rnk, _ = self._get_rank_thread(src)\n",
    "                send_buffers[s_rnk].append({'s': src, 'ci': tgt_data})\n",
    "            self.target_send_buffers.append(send_buffers)\n",
    "            \n",
    "    def _build_target_table(self):\n",
    "        \"\"\"\n",
    "        From target_send_buffers build target_table as done by EventDeliveryManager::distribute_target_data_buffers_().\n",
    "        \n",
    "        In the table here, we use the absolute node id, not the local id. Since we do not use local id, instead of a\n",
    "        vector index by lid we use a dict indexed by node id. Map elements are lists of Target entries.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.target_table = []\n",
    "        for rk in range(self.n_mpi):\n",
    "            incoming = []\n",
    "            for t_rk, in_buffer in enumerate(self.target_send_buffers):\n",
    "                for entry in in_buffer[rk]:\n",
    "                    entry['tgt_rk'] = t_rk\n",
    "                    incoming.append(entry)\n",
    "            # incoming now has all connection information sent to this rank\n",
    "            tt = [{} for _ in range(self.n_thr)]\n",
    "            for entry in incoming:\n",
    "                s = entry['s']\n",
    "                ci = entry['ci']\n",
    "                _, s_thr = self._get_rank_thread(s)\n",
    "                if s not in tt[s_thr]:\n",
    "                    tt[s_thr][s] = []\n",
    "                tt[s_thr][s].append((entry['tgt_rk'], entry['ci']))\n",
    "            self.target_table.append(tt)\n",
    "            \n",
    "    def print_source_table(self):\n",
    "        print('Source Table')\n",
    "        for rk, rst in enumerate(self.source_table):\n",
    "            for tr, trst in enumerate(rst):\n",
    "                s, t, _ = zip(*trst)\n",
    "                lbl = f'Rank {rk}, Thread {tr}'\n",
    "                w_lbl = len(lbl)\n",
    "                print(lbl, '  Idx:', end='')\n",
    "                for v in range(len(s)): print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, '  Src:', end='')\n",
    "                for v in s: print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, '  Tgt:', end='')\n",
    "                for v in t: print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print()\n",
    "\n",
    "    def print_compressible_sources(self):\n",
    "        print('Compressible Sources')\n",
    "        for rk, rst in enumerate(self.compressible_sources):\n",
    "            for tr, trst in enumerate(rst):\n",
    "                s, ix = zip(*trst)\n",
    "                lbl = f'Rank {rk}, Thread {tr}'\n",
    "                w_lbl = len(lbl)\n",
    "                print(lbl, '       Src:', end='')\n",
    "                for v in s: print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, '  1st LCID:', end='')\n",
    "                for v in ix: print(f'{v[1]:4d}', end='')\n",
    "                print()\n",
    "                print()\n",
    "\n",
    "    def print_compressed_spike_data_map(self):\n",
    "        print('Compressed Spike Data Map')\n",
    "        for rk, csdm in enumerate(self.compressed_spike_data_map):\n",
    "            s, ix = zip(*sorted(csdm.items()))\n",
    "            lbl = f'Rank {rk}'\n",
    "            w_lbl = len(lbl)\n",
    "            print(lbl, '     Src:', end='')\n",
    "            for v in s: print(f'{v:4d}', end='')\n",
    "            print()\n",
    "            print(' '*w_lbl, ' CSD Idx:', end='')\n",
    "            for v in ix: print(f'{v:4d}', end='')\n",
    "            print()\n",
    "            print()\n",
    "\n",
    "    def print_compressed_spike_data(self):\n",
    "        print('Compressed Spike Data')\n",
    "        for rk, csd in enumerate(self.compressed_spike_data):\n",
    "            n = len(csd)\n",
    "            lbl = f'Rank {rk}'\n",
    "            w_lbl = len(lbl)\n",
    "            print(lbl, '   Idx:', end='')\n",
    "            for v in range(n): print(f'{v:6d} |', end='')\n",
    "            print()\n",
    "            print(' '*w_lbl, ' TT LC:', end='')\n",
    "            for v in csd: \n",
    "                if v[0]:\n",
    "                    d = v[0][0]\n",
    "                    print(f'{d[\"tgt_thr\"]:3d}{d[\"lcid\"]:3d} |', end='')\n",
    "                elif v[1]:\n",
    "                    d = v[1][0]\n",
    "                    print(f'{d[\"tgt_thr\"]:3d}{d[\"lcid\"]:3d} |', end='')\n",
    "            print()\n",
    "            print(' '*w_lbl, ' TT LC:', end='')\n",
    "            for v in csd: \n",
    "                if v[0] and v[1]:\n",
    "                    d = v[1][0]\n",
    "                    print(f'{d[\"tgt_thr\"]:3d}{d[\"lcid\"]:3d} |', end='')\n",
    "                else:\n",
    "                    print('       |', end='')\n",
    "            print()\n",
    "            print()\n",
    "            \n",
    "    def print_target_send_buffers(self):\n",
    "        print('Target send buffers')\n",
    "        for from_rk, rst in enumerate(self.target_send_buffers):\n",
    "            for to_rk, trst in enumerate(rst):\n",
    "                df = pd.DataFrame.from_records(trst)\n",
    "                lbl = f'From rank {from_rk} To rank {to_rk}:'\n",
    "                w_lbl = len(lbl)\n",
    "                print(lbl, '     Src:', end='')\n",
    "                for v in df.s: print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, ' CSD Idx:', end='')\n",
    "                for v in df.ci: print(f'{v:4d}', end='')\n",
    "                print()\n",
    "                print()\n",
    "                \n",
    "    def print_target_send_buffers_sizes(self):\n",
    "        print('Target send buffers sizes')\n",
    "        for from_rk, rst in enumerate(self.target_send_buffers):\n",
    "            for to_rk, trst in enumerate(rst):\n",
    "                print(f'From rank {from_rk} To rank {to_rk}: {len(trst):3d}')\n",
    "                \n",
    "    def print_target_table(self):\n",
    "        print('Target Table')\n",
    "        for rk, ttr in enumerate(self.target_table):\n",
    "            for thr, tt in enumerate(ttr):\n",
    "                s, tl = zip(*sorted(tt.items()))\n",
    "                lbl = f'Rank {rk}, Thread {thr}'\n",
    "                w_lbl = len(lbl)\n",
    "                print(lbl, '   Src:', end='')\n",
    "                for v in s: print(f'{v:6d} |', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, ' TR CI:', end='')\n",
    "                for v in tl:\n",
    "                    assert 1 <= len(v) <= 2, \"Print code cannot handle anything else\"\n",
    "                    print(f'{v[0][0]:3d}{v[0][1]:3d} |', end='')\n",
    "                print()\n",
    "                print(' '*w_lbl, ' TR CI:', end='')\n",
    "                for v in tl:\n",
    "                    if len(v) > 1:\n",
    "                        print(f'{v[1][0]:3d}{v[1][1]:3d} |', end='')\n",
    "                    else:\n",
    "                        print('       |', end='')\n",
    "                print()\n",
    "                print()\n",
    "                \n",
    "    def print_connectivity(self):\n",
    "        cm = {}\n",
    "        for s, t in self.conns:\n",
    "            if s not in cm:\n",
    "                cm[s] = []\n",
    "            cm[s].append(t)\n",
    "        mx = max(len(tl) for tl in cm.values())\n",
    "        s, tl = zip(*sorted(cm.items()))\n",
    "        print('Src:', end='')\n",
    "        for v in s: print(f'{v:3d} |', end='')\n",
    "        print()\n",
    "        for tr in range(mx):\n",
    "            print('Tgt:', end='')\n",
    "            for tll in tl:\n",
    "                try:\n",
    "                    print(f'{tll[tr]:3d} |', end='')\n",
    "                except IndexError:\n",
    "                    print('    |', end='')\n",
    "            print()\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35420a77-a9c6-4823-a2c6-49474119c2b9",
   "metadata": {},
   "source": [
    "## Trace spike transmission \n",
    "\n",
    "- Build full connectivity tables for bad connectivty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "750ca075-80d1-4d2e-a0f9-917d91952dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bad_ct = ConnTables(zip(bad_sources, tgts), 4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9e84f-05b9-4304-9177-0d1c3c68fa2d",
   "metadata": {},
   "source": [
    "- Look first at overall connectivity.\n",
    "- Since we know that spikes from even-numbered neurons cause problems, consider 44 as source. It has targets 6, 44, and 47."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4d31caa1-9abb-4558-b24f-a0cb0aa2723b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src:  3 |  5 |  9 | 10 | 11 | 15 | 19 | 21 | 25 | 27 | 29 | 30 | 33 | 34 | 35 | 36 | 37 | 38 | 40 | 41 | 42 | 44 | 45 | 46 | 47 | 48 | 49 | 50 |\n",
      "Tgt: 25 | 26 |  5 |  1 | 11 | 19 |  7 | 21 | 10 | 16 | 18 | 40 | 12 | 41 | 43 | 15 | 14 | 24 | 42 |  3 | 31 |  6 | 17 |  8 | 50 | 46 |  2 | 22 |\n",
      "Tgt: 28 | 35 |  9 |    |    |    |    | 37 |    | 20 | 38 |    |    |    |    | 33 | 32 | 27 |    |  4 |    | 44 | 34 | 13 |    |    | 30 |    |\n",
      "Tgt: 36 |    | 39 |    |    |    |    |    |    | 23 |    |    |    |    |    | 49 |    |    |    | 29 |    | 47 |    |    |    |    |    |    |\n",
      "Tgt:    |    |    |    |    |    |    |    |    | 48 |    |    |    |    |    |    |    |    |    | 45 |    |    |    |    |    |    |    |    |\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58a33d0-36e4-4d37-8033-7b3d9de1a157",
   "metadata": {},
   "source": [
    "- Transmission starts with the target table.\n",
    "- We find source 44 in the target table for Rank 0, Thread 0.\n",
    "- I has two entries: The first points to target rank 0, compressed spike data entry 7, and rank 1, csd entry 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "4ac4858f-3cfe-4ac4-bc37-1df47d39b052",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Table\n",
      "Rank 0, Thread 0    Src:    36 |    40 |    44 |    48 |\n",
      "                  TR CI:  1  5 |  0 12 |  0  7 |  0 15 |\n",
      "                  TR CI:       |       |  1 17 |       |\n",
      "\n",
      "Rank 0, Thread 1    Src:    10 |    30 |    34 |    38 |    42 |    46 |    50 |\n",
      "                  TR CI:  1  2 |  0  2 |  1  4 |  0  5 |  1 16 |  0  8 |  0 17 |\n",
      "                  TR CI:       |       |       |  1 15 |       |  1  8 |       |\n",
      "\n",
      "Rank 1, Thread 0    Src:     5 |     9 |    21 |    25 |    29 |    33 |    37 |    41 |    45 |    49 |\n",
      "                  TR CI:  0  9 |  1  1 |  1  3 |  0 10 |  0 11 |  0  3 |  0  4 |  0  6 |  0 13 |  0 16 |\n",
      "                  TR CI:  1  9 |       |       |       |       |       |       |  1  6 |  1  7 |       |\n",
      "\n",
      "Rank 1, Thread 1    Src:     3 |    11 |    15 |    19 |    27 |    35 |    47 |\n",
      "                  TR CI:  0  0 |  1 10 |  1 11 |  1 12 |  0  1 |  1 14 |  0 14 |\n",
      "                  TR CI:  1  0 |       |       |       |  1 13 |       |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_target_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a2b3f-2699-4a2b-a5d2-3a54a5595252",
   "metadata": {},
   "source": [
    "In the compressed spike data, we find\n",
    "- on rank 0, index 7, entries pointing to thread 0, LCID 10 and thread 1, LCID 6\n",
    "- on rank 1, index 17, and entry pointing to thread 1, LCID 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "cbd5d820-525e-404a-8458-4338202cdf32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Spike Data\n",
      "Rank 0    Idx:     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 |    11 |    12 |    13 |    14 |    15 |    16 |    17 |\n",
      "        TT LC:  0  0 |  0  2 |  0  5 |  0  6 |  0  7 |  0  8 |  0  9 |  0 10 |  0 11 |  1  0 |  1  1 |  1  2 |  1  5 |  1  7 |  1  8 |  1  9 |  1 10 |  1 12 |\n",
      "        TT LC:       |       |       |       |  1  4 |       |       |  1  6 |       |       |       |       |       |       |       |       |       |       |\n",
      "\n",
      "Rank 1    Idx:     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 |    11 |    12 |    13 |    14 |    15 |    16 |    17 |\n",
      "        TT LC:  0  0 |  0  1 |  0  3 |  0  4 |  0  6 |  0  7 |  0  9 |  0 11 |  0 12 |  1  0 |  1  2 |  1  3 |  1  4 |  1  5 |  1  6 |  1  8 |  1 10 |  1 11 |\n",
      "        TT LC:       |  1  1 |       |       |       |  1  7 |  1  9 |       |       |       |       |       |       |       |       |       |       |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_compressed_spike_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5049df-7b01-46f0-a288-0644a63286aa",
   "metadata": {},
   "source": [
    "- On rank 0, thread 0, LCID 10, we find target 44\n",
    "- On rank 0, thread 1, LCID 6, we find target 6\n",
    "- On rank 1, thread 1, LCID 11, we find target 47\n",
    "\n",
    "Thus, we have deliverd to all targets of source 44.\n",
    "\n",
    "We only use the source table or looking up targets here for convenience, actual spike delivery is via connection infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "39feeba3-b333-464f-a979-28052bdecc67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Table\n",
      "Rank 0, Thread 0   Idx:   0   1   2   3   4   5   6   7   8   9  10  11\n",
      "                   Src:   3   3  27  27  27  30  33  37  38  41  44  46\n",
      "                   Tgt:  28  36  16  20  48  40  12  32  24   4  44   8\n",
      "\n",
      "Rank 0, Thread 1   Idx:   0   1   2   3   4   5   6   7   8   9  10  11  12\n",
      "                   Src:   5  25  29  29  37  40  44  45  47  48  49  49  50\n",
      "                   Tgt:  26  10  18  38  14  42   6  34  50  46   2  30  22\n",
      "\n",
      "Rank 1, Thread 0   Idx:   0   1   2   3   4   5   6   7   8   9  10  11  12\n",
      "                   Src:   3   9   9  10  21  21  34  36  36  41  41  45  46\n",
      "                   Tgt:  25   5   9   1  21  37  41  33  49  29  45  17  13\n",
      "\n",
      "Rank 1, Thread 1   Idx:   0   1   2   3   4   5   6   7   8   9  10  11\n",
      "                   Src:   5   9  11  15  19  27  35  36  38  41  42  44\n",
      "                   Tgt:  35  39  11  19   7  23  43  15  27   3  31  47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_source_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b5bb9-111c-49ad-906e-1884985c55f9",
   "metadata": {},
   "source": [
    "- For a different case, consider source 3 with targets 25, 28 and 36.\n",
    "    - From the target table of rank 1/thread 1, we find entries for rank 0, csd index 0 and rank 1, csd index 0.\n",
    "    - Both point to target thread 0, LCID 0\n",
    "    - On rank 0/thread 0 we find target 28 at LCID 0. We also notice that the next entry also has source 3, so we also deliver to 36\n",
    "    - On rank 1/thread 0 we find target 25 at LCID 0.\n",
    "    - We have found all targets, 25, 28 and 36."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce64c11-b4fa-423e-b865-9d4f030db7a0",
   "metadata": {},
   "source": [
    "### How are the tables built?\n",
    "\n",
    "- While connections are created on the target process, source_table is built in parallel to connection infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8e81d5c2-9328-41af-b9ab-2dfd17cc2341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Table\n",
      "Rank 0, Thread 0   Idx:   0   1   2   3   4   5   6   7   8   9  10  11\n",
      "                   Src:   3   3  27  27  27  30  33  37  38  41  44  46\n",
      "                   Tgt:  28  36  16  20  48  40  12  32  24   4  44   8\n",
      "\n",
      "Rank 0, Thread 1   Idx:   0   1   2   3   4   5   6   7   8   9  10  11  12\n",
      "                   Src:   5  25  29  29  37  40  44  45  47  48  49  49  50\n",
      "                   Tgt:  26  10  18  38  14  42   6  34  50  46   2  30  22\n",
      "\n",
      "Rank 1, Thread 0   Idx:   0   1   2   3   4   5   6   7   8   9  10  11  12\n",
      "                   Src:   3   9   9  10  21  21  34  36  36  41  41  45  46\n",
      "                   Tgt:  25   5   9   1  21  37  41  33  49  29  45  17  13\n",
      "\n",
      "Rank 1, Thread 1   Idx:   0   1   2   3   4   5   6   7   8   9  10  11\n",
      "                   Src:   5   9  11  15  19  27  35  36  38  41  42  44\n",
      "                   Tgt:  35  39  11  19   7  23  43  15  27   3  31  47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_source_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b848d-e8a9-4ed7-9c02-83d206d2cf64",
   "metadata": {},
   "source": [
    "- On every thread, we then check for repeated sources and create a map of sources to the first index in the source table for the given thread with a connection for a given source\n",
    "- Not shown here is that a \"has more targets\" marker is set in connection objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "41b7fda1-387e-4068-968a-15d4369a8ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressible Sources\n",
      "Rank 0, Thread 0        Src:   3  27  30  33  37  38  41  44  46\n",
      "                   1st LCID:   0   2   5   6   7   8   9  10  11\n",
      "\n",
      "Rank 0, Thread 1        Src:   5  25  29  37  40  44  45  47  48  49  50\n",
      "                   1st LCID:   0   1   2   4   5   6   7   8   9  10  12\n",
      "\n",
      "Rank 1, Thread 0        Src:   3   9  10  21  34  36  41  45  46\n",
      "                   1st LCID:   0   1   3   4   6   7   9  11  12\n",
      "\n",
      "Rank 1, Thread 1        Src:   5   9  11  15  19  27  35  36  38  41  42  44\n",
      "                   1st LCID:   0   1   2   3   4   5   6   7   8   9  10  11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_compressible_sources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78476be3-2137-488d-bb08-4c4117400ff1",
   "metadata": {},
   "source": [
    "- On each rank, we now integrate the data from the compressible sources table across threads on each rank\n",
    "- We end up with two data structures:\n",
    "    - For each unique source node, Compressed Spike Data contains a list of entries pointing to the source table (and thus connection infrastructure) location of the first target of the source on any given thread.\n",
    "    - Compressed Spike Data Map maps source node ids to indices in the Compressed Spike Data array\n",
    "- See also lookup examples above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9ebe6a2e-e84d-44e2-80ee-265e5e906050",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Spike Data Map\n",
      "Rank 0      Src:   3   5  25  27  29  30  33  37  38  40  41  44  45  46  47  48  49  50\n",
      "        CSD Idx:   0   9  10   1  11   2   3   4   5  12   6   7  13   8  14  15  16  17\n",
      "\n",
      "Rank 1      Src:   3   5   9  10  11  15  19  21  27  34  35  36  38  41  42  44  45  46\n",
      "        CSD Idx:   0   9   1   2  10  11  12   3  13   4  14   5  15   6  16  17   7   8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_compressed_spike_data_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "97e19350-23fa-4c8c-b105-f3ddf1de61eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed Spike Data\n",
      "Rank 0    Idx:     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 |    11 |    12 |    13 |    14 |    15 |    16 |    17 |\n",
      "        TT LC:  0  0 |  0  2 |  0  5 |  0  6 |  0  7 |  0  8 |  0  9 |  0 10 |  0 11 |  1  0 |  1  1 |  1  2 |  1  5 |  1  7 |  1  8 |  1  9 |  1 10 |  1 12 |\n",
      "        TT LC:       |       |       |       |  1  4 |       |       |  1  6 |       |       |       |       |       |       |       |       |       |       |\n",
      "\n",
      "Rank 1    Idx:     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 |    10 |    11 |    12 |    13 |    14 |    15 |    16 |    17 |\n",
      "        TT LC:  0  0 |  0  1 |  0  3 |  0  4 |  0  6 |  0  7 |  0  9 |  0 11 |  0 12 |  1  0 |  1  2 |  1  3 |  1  4 |  1  5 |  1  6 |  1  8 |  1 10 |  1 11 |\n",
      "        TT LC:       |  1  1 |       |       |       |  1  7 |  1  9 |       |       |       |       |       |       |       |       |       |       |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_compressed_spike_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa8b7c-42ee-45e7-854e-31dab2b9365e",
   "metadata": {},
   "source": [
    "- The data in the compressed spike data map is then transmitted, together with the source node id, to the presynaptic rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c67b9e11-b8b8-48c7-b65e-45717a239387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target send buffers\n",
      "From rank 0 To rank 0:      Src:  30  38  44  46  40  48  50\n",
      "                        CSD Idx:   2   5   7   8  12  15  17\n",
      "\n",
      "From rank 0 To rank 1:      Src:   3  27  33  37  41   5  25  29  45  47  49\n",
      "                        CSD Idx:   0   1   3   4   6   9  10  11  13  14  16\n",
      "\n",
      "From rank 1 To rank 0:      Src:  10  34  36  46  38  42  44\n",
      "                        CSD Idx:   2   4   5   8  15  16  17\n",
      "\n",
      "From rank 1 To rank 1:      Src:   3   9  21  41  45   5  11  15  19  27  35\n",
      "                        CSD Idx:   0   1   3   6   7   9  10  11  12  13  14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_target_send_buffers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc47018-6849-49cd-aded-580e1f196c5a",
   "metadata": {},
   "source": [
    "- From this information, the presynaptic ranks can then build their target tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "abb92993-055b-4ab5-bb88-188173218250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Table\n",
      "Rank 0, Thread 0    Src:    36 |    40 |    44 |    48 |\n",
      "                  TR CI:  1  5 |  0 12 |  0  7 |  0 15 |\n",
      "                  TR CI:       |       |  1 17 |       |\n",
      "\n",
      "Rank 0, Thread 1    Src:    10 |    30 |    34 |    38 |    42 |    46 |    50 |\n",
      "                  TR CI:  1  2 |  0  2 |  1  4 |  0  5 |  1 16 |  0  8 |  0 17 |\n",
      "                  TR CI:       |       |       |  1 15 |       |  1  8 |       |\n",
      "\n",
      "Rank 1, Thread 0    Src:     5 |     9 |    21 |    25 |    29 |    33 |    37 |    41 |    45 |    49 |\n",
      "                  TR CI:  0  9 |  1  1 |  1  3 |  0 10 |  0 11 |  0  3 |  0  4 |  0  6 |  0 13 |  0 16 |\n",
      "                  TR CI:  1  9 |       |       |       |       |       |       |  1  6 |  1  7 |       |\n",
      "\n",
      "Rank 1, Thread 1    Src:     3 |    11 |    15 |    19 |    27 |    35 |    47 |\n",
      "                  TR CI:  0  0 |  1 10 |  1 11 |  1 12 |  0  1 |  1 14 |  0 14 |\n",
      "                  TR CI:  1  0 |       |       |       |  1 13 |       |       |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bad_ct.print_target_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766348d9-53ee-4dc0-8373-7c1536c0ecdc",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "- Comparison with debugging output indicdates that all steps up to and including building the compressed spike data (map) works.\n",
    "- Also filling of send buffers and reading them out works in principle.\n",
    "- But for some reason a resizing of the target data transmission buffers happens, which causes double transmission of connections and thus the problem at hand.\n",
    "- Note also that the heuristics for determining the initial target buffer size are definitely wrong for compressed spikes and dubious otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec6500-abcb-48d9-8f69-74f4d97babf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
